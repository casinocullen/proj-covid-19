// Change the name of this script to match the data source. This will make it easier to know what script you are working on when its open.

---
title: "[Data source name] - cleanup and import script"
output: html_notebook
---

```{r}
# Set working directory to location of this script
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
```

# Dependencies
Any special libraries that are not part of the CORI install.R script
```{r include=FALSE}

# Include CORI base script
source("../base/global.R")

# Install a specific version
devtools::install_version("[package name]", version = "[version number]")

# Install latest version
require([package name])

# Load the package
require([package name])
```


# Download source file/s and store in s3
Usually you would just use one of these and remove the others.
Only run this once. From then on, use the S3 version if needed, unless there is a new version of the file

## Single file
```{r}
url_to_s3(
  url = "[url]", 
  filename = "[filename]", 
  s3path = "source/[sourcename]/", 
  s3bucket = "cori-layers"
  )
```

## Multiple files using state codes
`states.cont.fips` is also available.
`file` will probably need to be updated

```{r}
baseurl = ""
path = "./source/"
  for (state in states.cont) {
    file = paste0("[prefix]",state,"[sufix].[ext]")
    if(!file.exists(paste0(baseurl,file))){
      url_to_s3(
        url = "[url]", 
        filename = "[filename]", 
        s3path = "source/[sourcename]/", 
        s3bucket = "cori-layers"
  )
    }
  }
rm(baseurl,path,i,file)
```

## Multiple files using list of urls
```{r}
ouput.dir = "output/"

urls <- c(
'[url1]',
'[url2]',
'[url3]'
)

if(!file.exists(ouput.dir)) {
  dir.create(ouput.dir, recursive = TRUE)
}
for (url in urls){
  url_to_s3(
  url = url, 
  filename = "[filename]", 
  s3path = "source/[sourcename]/", 
  s3bucket = "cori-layers"
  )
}

```

## API in JSON format (single page)
```{r}
json.[name] = fromJSON("url")
[name] <- json.[name][['data']][['data']] # This removes two levels of hierarchy. Each feed will need something different
```

## API in JSON format (multiple pages)
```{r}
# Get data structure and create empty table
json.[name] = fromJSON("url") # All we need is one record here, since we are just going to delete it
[name] <- json.[name][['data']][['data']] # This removes two levels of hierarchy. Each feed will need something different
[name] <- [name][0,] # Delete content, the following for loop will get all the pages

for (i in [pages]) {
  json <- fromJSON(paste0("[url"))
  json_data <- json[['data']][['data']]
  [name] <- rbind(json.[name],json_data)
  print(state)
}
```


# Check file headers for consistency (if multiple source files)
If you are combining multiple source files
```{r}
header1 <- read_excel("../output/[file1]", skip = 0, n_max = 1)
header2 <- read_excel("../output/[file2]", skip = 0, n_max = 1)
header3 <- read_excel("../output/[file3]", skip = 0, n_max = 1)

headers <- list(header1, header2, header3)

print("These files have different headers...")
for (header in headers) {
  if(!identical(header.2015, header)) {
    print("problem!")
  }
}
print("The rest are identical")
```


# Read in file/s

## Unzip if needed
```{r}
unzip("./source/[filename]", exdir="./source/[filename]", overwrite=TRUE)
```

## Single csv
You don't need to download the file, you can just pull it right into R. Just use the appropriat read function from https://readr.tidyverse.org/ or whatever you need based on the file type.
```{r}
# Get source data from S3 files
source <- read_csv(get_object("s3://cori-layers/source/[layer]/[remote file]"))
```

## Single xls
```{r}
# Get from s3
save_object("s3://cori-layers/source/[layer]/[remote file]", file = "./source/[remote file]")

# Check if there are multiple sheets
excel_sheets("./source/[filename].[ext]")

# Get a preview of column names
names(read_excel("./source/[filename].[ext]", sheet = "[sheet name]", n_max = 0))

# Get data
source <- read_excel("./source/[filename].[ext]", sheet = "[sheet name]")
```

## Multiple files
```{r}
# [TODO]
```


# Check data to make sure it is consistent and in a usable format
## NULL vs NA vs empty values
```{r}
# [TODO]
```

## Data types
```{r}
# [TODO]
```


# Clean up column names


# Clean data

# Create Postgres table
```{r}
x.date <- as.character(Sys.Date(), format = '%Y%m%d')
x.date

dbWriteTable(coririsi, paste0("[table name]","_",x.date), [R table], row.names = FALSE, overwrite = TRUE)
```

############################################################
## EOF 
############################################################
